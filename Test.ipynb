{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7774d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfb8155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 1, 96000)\n"
     ]
    }
   ],
   "source": [
    "scp = np.loadtxt(\"dev_as_test.lst\", dtype=str)\n",
    "def read_data(path):\n",
    "    speech, _ = sf.read(path)\n",
    "#     print(_)\n",
    "    data = np.reshape(speech, [1, -1])\n",
    "    if data.shape[1] % 96000:\n",
    "        if data.shape[1] * 2 < 96000:\n",
    "            data = np.tile(data, (1, 96000 // data.shape[1]))\n",
    "        data = np.hstack([data, data[:, :96000 - data.shape[1] % 96000]])\n",
    "    data = np.split(data, data.shape[1] / 96000, axis=1)\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    return data\n",
    "#     print(data.shape)\n",
    "\n",
    "scp = [\"LA_D_1000265.flac\", \"LA_D_3262859.flac\",  \"LA_D_3266246.flac\", \"LA_D_3267906.flac\", \"LA_D_3260017.flac\", \"LA_D_3263334.flac\", \"LA_D_3266332.flac\", \"LA_D_3268182.flac\", \"LA_D_3260123.flac\", \"LA_D_3263579.flac\",  \"LA_D_3266553.flac\", \"LA_D_3268836.flac\", \"LA_D_3260640.flac\", \"LA_D_3263795.flac\", \"LA_D_3266637.flac\", \"LA_D_3269593.flac\", \"LA_D_3260902.flac\", \"LA_D_3264000.flac\", \"LA_D_3266852.flac\", \"LA_D_3261219.flac\", \"LA_D_3264696.flac\", \"LA_D_3267050.flac\", \"LA_D_3262004.flac\", \"LA_D_3264952.flac\", \"LA_D_3267875.flac\"]\n",
    "scp_ = []\n",
    "for scp__ in scp:\n",
    "    scp_.append(os.path.join(\"wav\", scp__))\n",
    "scp = scp_\n",
    "del scp_\n",
    "# print(scp)\n",
    "test_data = []\n",
    "for i in scp:\n",
    "    test_data.append(read_data(i))\n",
    "\n",
    "test_frame_num = len(test_data)\n",
    "test_data = np.concatenate(test_data, axis=0)\n",
    "\n",
    "# test_data, scp as test names, test_frame_num\n",
    "# print(test_data)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3987ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 2)\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "genuine_labels = np.zeros((120, 2), dtype=np.float32)\n",
    "spoof_labels = np.zeros((120, 2), dtype=np.float32)\n",
    "\n",
    "genuine_labels[:, 0] = 1.0 # [1, 0]\n",
    "spoof_labels[:, 1] = 1.0 # [0, 1]\n",
    "\n",
    "labels = np.concatenate((genuine_labels, spoof_labels), axis=0)\n",
    "\n",
    "print(labels.shape)\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6125d881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 1, 96000)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "inputs = np.reshape(test_data, [26, 1, 96000]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fd377fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros(10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d77518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1044170",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(64, 256, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab4cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 86, 10])\n",
      "torch.Size([64, 86, 10])\n",
      "torch.Size([128, 86, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomtony/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "# print(input.shape)\n",
    "conv1 =  torch.nn.Conv1d(256, 86, 9, stride=2, dilation=2, padding=2)\n",
    "output = conv1(input)\n",
    "print(output.shape)\n",
    "\n",
    "# output = output[:,:,:10]\n",
    "# noise_means = torch.randn(64, 86, 10)\n",
    "# output_l = output[:,:,output.shape[2]-10:]\n",
    "# print(type(output))\n",
    "# output = torch.cat((output, noise_means), 0)\n",
    "print(output.shape)\n",
    "\n",
    "pool1 = torch.nn.MaxPool1d(3, stride=1, dilation=1, padding=1)\n",
    "output = pool1(output)\n",
    "# print(output.shape)\n",
    "output = torch.cat((output, output), 0)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f201f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 29, 3])\n",
      "torch.Size([128, 29, 1])\n"
     ]
    }
   ],
   "source": [
    "conv2 = torch.nn.Conv1d(86, 29, 4, stride=2, dilation=2, padding=1)\n",
    "output_ = conv2(output)\n",
    "print(output_.shape)\n",
    "pool2 = torch.nn.MaxPool1d(3,stride=1)\n",
    "output__ = pool2(output_)\n",
    "print(output__.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88fa45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "# import os\n",
    "# # print(os.path.abspath(os.getcwd()))\n",
    "# # waveform, sample_rate = torchaudio.load(\"/mnt/c/Users/YH-ANZHE/D1_1002601.wav\")\n",
    "# waveform = test_data[0]\n",
    "# sample_rate = 16000\n",
    "# print(waveform.shape, sample_rate)\n",
    "# stft_result = torch.stft(waveform[:,10:], sample_rate, win_length=10)\n",
    "# print(stft_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca3409c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-256b1afefa7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "waveform = test_data[0]\n",
    "sample_rate = 16000\n",
    "import librosa\n",
    "import math\n",
    "\n",
    "\n",
    "def extract_features(waveform, sample_rate):\n",
    "    # print(waveform.numpy())\n",
    "    print(len(waveform[0]))\n",
    "    n_fft = 1024\n",
    "    win_length = int(np.ceil(0.025*sample_rate))\n",
    "    hop_length = int(np.ceil(0.010*sample_rate))\n",
    "    window = \"hamming\"\n",
    "\n",
    "    n_mels = 256\n",
    "    fmin = 20\n",
    "    fmax = 8000\n",
    "    X = librosa.stft(waveform[0], n_fft, hop_length, win_length, window, center=True)\n",
    "#     print(np.abs(X).shape)\n",
    "    frames = np.log(librosa.feature.melspectrogram(y=waveform[0], sr=sample_rate, S=X, n_mels=n_mels, fmin=fmin, fmax=fmax) + 1e-6)\n",
    "    print(X.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     noise=np.random.normal(0, 10, waveform.shape[1]).reshape(-1, waveform.shape[1])\n",
    "#     N = librosa.stft(noise[0], n_fft, hop_length, win_length, window, center=True)\n",
    "    \n",
    "# #     print(noise)\n",
    "#     SNM = 1/(1 + np.exp(-np.abs(X)/np.abs(N)))\n",
    "#     print(SNM.shape)\n",
    "#     print(frames.shape)\n",
    "#     frames = np.log(librosa.feature.melspectrogram(y=waveform[0]+noise[0], sr=sample_rate, S=SNM, n_mels=n_mels, fmin=fmin, fmax=fmax) + 1e-6)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    window_size = 31\n",
    "    window_hop = 31\n",
    "    start_frame = window_size \n",
    "    end_frame = window_hop * math.floor(float(frames.shape[1]) / window_hop/2)\n",
    "    window = frames[:, end_frame: end_frame+window_size]\n",
    "    \n",
    "    noises_features = np.mean(abs(frames[:, :10]), axis=1)\n",
    "    \n",
    "    return abs(window), noises_features\n",
    "\n",
    "\n",
    "window, noises_features = extract_features(waveform, sample_rate)\n",
    "\n",
    "# window_size = 31\n",
    "# window_hop = 31\n",
    "# start_frame = window_size \n",
    "# end_frame = window_hop * math.floor(float(frames.shape[1]) / window_hop/2)\n",
    "\n",
    "    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# inputs = []\n",
    "# window = frames[:, end_frame: end_frame+window_size]\n",
    "# assert window.shape == (n_mels, window_size)\n",
    "# inputs.append(abs(window))\n",
    "plt.imshow(window, cmap='jet', origin='lower', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# noises = abs(frames[:, :10])\n",
    "# print(noises.shape)\n",
    "# noises_features = np.mean(noises, axis=1)\n",
    "# print(noises_features.shape)\n",
    "# for frame_idx in range(start_frame, end_frame, window_hop):\n",
    "\n",
    "#     window = frames[:, frame_idx-window_size:frame_idx]\n",
    "#     assert window.shape == (n_mels, window_size)\n",
    "#     print('classify window', frame_idx, window.shape)\n",
    "# #     print(window)\n",
    "#     inputs.append(abs(window))\n",
    "#     plt.imshow(abs(window), cmap='jet', origin='lower', aspect='auto')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37df7e14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b640ed646bb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0minputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0minputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# print(inputs_.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, (9,9), stride=(1, 1), padding='same'),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d((3,3), stride=(3,3), ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, (4,4), stride=(1,1), padding='same'),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d((3,3), stride=(3, 3), ceil_mode=False),\n",
    "        )\n",
    "\n",
    "inputs_ = np.array(inputs)\n",
    "inputs_ = inputs_.reshape(-1, 1, 256, 31)\n",
    "# print(inputs_.shape)\n",
    "inputs_ = torch.from_numpy(inputs_)\n",
    "# print(inputs.shape)\n",
    "# inputs = torch.reshape(inputs, (11, 1, 256, -1))\n",
    "# print(torch.FloatTensor(inputs).shape)\n",
    "outputs = cnn_layers(torch.tensor(inputs_))\n",
    "\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb35f1f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3f2247eae348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minputs__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoises_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0moutputs__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "fc3 = nn.Sequential(\n",
    "        nn.Linear(128*28*3+256, 1024),\n",
    "        nn.Linear(1024, 1024),\n",
    "        nn.Linear(1024, 256),\n",
    "    )\n",
    "\n",
    "inputs__ = torch.cat((outputs[0].flatten(), torch.from_numpy(noises_features).flatten()))\n",
    "outputs__ = fc3(inputs__)\n",
    "print(outputs__.shape)\n",
    "print(outputs__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e77d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN Network for SNM features 最终版本 219\n",
    "class CNN_SNM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, (9,9), stride=(1, 1), padding='same'),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d((3,3), stride=(3,3), ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, (4,4), stride=(1,1), padding='same'),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d((3,3), stride=(3, 3), ceil_mode=False),\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(128*28*3+256, 1024),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.Linear(1024, 256),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, noises_features):\n",
    "        result = self.cnn_layers(x)\n",
    "        result = self.fc3(torch.cat((result[0].flatten(), torch.from_numpy(noises_features).flatten())))\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed520c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96000\n",
      "(513, 601)\n",
      "cnn_layers.0.weight : torch.Size([64, 1, 9, 9])\n",
      "cnn_layers.0.bias : torch.Size([64])\n",
      "cnn_layers.3.weight : torch.Size([128, 64, 4, 4])\n",
      "cnn_layers.3.bias : torch.Size([128])\n",
      "fc3.0.weight : torch.Size([1024, 11008])\n",
      "fc3.0.bias : torch.Size([1024])\n",
      "fc3.1.weight : torch.Size([1024, 1024])\n",
      "fc3.1.bias : torch.Size([1024])\n",
      "fc3.2.weight : torch.Size([256, 1024])\n",
      "fc3.2.bias : torch.Size([256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomtony/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:439: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  /pytorch/aten/src/ATen/native/Convolution.cpp:660.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "input_data = test_data[0]\n",
    "window, noises_features = extract_features(input_data, 16000)\n",
    "window = window.reshape(-1, 1, 256, 31)\n",
    "net_SNM = CNN_SNM()\n",
    "SNMs = net_SNM(torch.tensor(window), noises_features)\n",
    "# print(SNMs)\n",
    "\n",
    "# get net_SNM paremeters:\n",
    "# print(list(net_SNM.parameters()))\n",
    "for name, parameters in net_SNM.named_parameters():\n",
    "    print(name, \":\", parameters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b187423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-e46e003b20b3>:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mat_ = mat1/mat2\n"
     ]
    }
   ],
   "source": [
    "mat1 = np.zeros((256, 31))\n",
    "mat2 = np.zeros((256, 31))\n",
    "\n",
    "mat_ = mat1/mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ebcca56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20])\n",
      "torch.Size([128, 1000])\n",
      "torch.Size([3]) torch.Size([3])\n",
      "tensor([0.8999, 0.7554, 0.7122], requires_grad=True) tensor([0.7109, 0.6803, 0.6709], grad_fn=<SigmoidBackward>) tensor([0., 0., 0.])\n",
      "tensor(1.1643, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(1.1643, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomtony/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:147: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(20, 1000)\n",
    "input = torch.randn(128, 20)\n",
    "print(input.shape)\n",
    "output = m(input)\n",
    "print(output.shape)\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "print(input.shape, target.shape)\n",
    "print(input, m(input), target)\n",
    "output = loss(m(input), target)\n",
    "# print(output.shape)\n",
    "print(output)\n",
    "output.backward()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c59e093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  1000\n",
      "data[0]:  1300\n",
      "data[0][0]:  49\n",
      "data[0][0][0]:  1\n"
     ]
    }
   ],
   "source": [
    "with open('../../Downloads/GRCNN-main/train_img_list.pkl', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True)\n",
    "print(\"data: \", len(data))\n",
    "print(\"data[0]: \", len(data[0]))\n",
    "print(\"data[0][0]: \", len(data[0][0]))\n",
    "print(\"data[0][0][0]: \", len(data[0][0][0])) # (1000, 1300, 49, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "c4094ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://gist.github.com/daskol/05439f018465c8fb42ae547b8cc8a77b\n",
    "# class Maxout(nn.Module):\n",
    "#     \"\"\"Class Maxout implements maxout unit introduced in paper by Goodfellow et al, 2013.\n",
    "    \n",
    "#     :param in_feature: Size of each input sample.\n",
    "#     :param out_feature: Size of each output sample.\n",
    "#     :param n_channels: The number of linear pieces used to make each maxout unit.\n",
    "#     :param bias: If set to False, the layer will not learn an additive bias.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, in_features, out_features, n_channels, bias=True):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.in_features = in_features\n",
    "#         self.out_features = out_features\n",
    "#         self.n_channels = n_channels\n",
    "\n",
    "#         print(\"n_channels * out_features, in_features: \", n_channels * out_features, in_features)\n",
    "\n",
    "#         self.weight = nn.Parameter(torch.Tensor(n_channels * out_features, in_features))\n",
    "        \n",
    "#         if bias:\n",
    "#             self.bias = nn.Parameter(torch.Tensor(n_channels * out_features))\n",
    "#         else:\n",
    "#             self.register_parameter('bias', None)\n",
    "            \n",
    "#         self.reset_parameters()\n",
    "    \n",
    "#     def forward(self, input):\n",
    "#         print(\"input shape: \", input.shape)\n",
    "#         print(\"weight shape: \", self.weight.shape)\n",
    "#         a = nn.functional.linear(input, self.weight, self.bias)\n",
    "#         b = nn.functional.max_pool1d(a.unsqueeze(-3), kernel_size=self.n_channels)\n",
    "#         return b.squeeze()\n",
    "    \n",
    "#     def reset_parameters(self):\n",
    "#         irange = 0.005\n",
    "#         nn.init.uniform_(self.weight, -irange, irange)\n",
    "#         if self.bias is not None:\n",
    "#             nn.init.uniform_(self.bias, -irange, irange)\n",
    "    \n",
    "#     def extra_repr(self):\n",
    "#         return (f'in_features={self.in_features}, '\n",
    "#                 f'out_features={self.out_features}, '\n",
    "#                 f'n_channels={self.n_channels}, '\n",
    "#                 f'bias={self.bias is not None}')\n",
    "\n",
    "from torch.autograd import Function\n",
    "\n",
    "class Maxout(Function):\n",
    "\n",
    "    # Note that both forward and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input):\n",
    "        x = input\n",
    "        max_out=2    #Maxout Parameter\n",
    "        kernels = x.shape[1]  # to get how many kernels/output\n",
    "        feature_maps = int(kernels / max_out)\n",
    "        out_shape = (x.shape[0], feature_maps, max_out, x.shape[2], x.shape[3])\n",
    "#         print(x.shape)\n",
    "        x= x.view(out_shape)\n",
    "#         print(x.shape)\n",
    "        y, indices = torch.max(x[:, :, :], 2)\n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.indices=indices\n",
    "        ctx.max_out=max_out\n",
    "        return y\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input1,indices,max_out= ctx.saved_variables[0],Variable(ctx.indices),ctx.max_out\n",
    "        input=input1.clone()\n",
    "        for i in range(max_out):\n",
    "            a0=indices==i\n",
    "            input[:,i:input.data.shape[1]:max_out]=a0.float()*grad_output\n",
    "      \n",
    "\n",
    "        return input\n",
    "\n",
    "\n",
    "class ConvGRUCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Generate a convolutional GRU cell\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size, conv_filter, conv_stride, max_filter, max_stride):\n",
    "        super().__init__()\n",
    "#         padding = conv_filter // 2\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.reset_gate = nn.Conv2d(input_size, output_size, conv_filter, stride=conv_stride, padding=\"same\")\n",
    "        self.reset_gate_ = nn.Conv2d(output_size//2, output_size, conv_filter, stride=conv_stride, padding=\"same\")\n",
    "#         print(hidden_size, hidden_size//2, 3)\n",
    "        self.reset_maxout = Maxout.apply\n",
    "        self.update_gate = nn.Conv2d(input_size, output_size, conv_filter, stride=conv_stride, padding=\"same\")\n",
    "        self.update_gate_ = nn.Conv2d(output_size//2, output_size, conv_filter, stride=conv_stride, padding=\"same\")\n",
    "        self.update_maxout = Maxout.apply\n",
    "        self.out_gate = nn.Conv2d(input_size, output_size, conv_filter, stride=conv_stride, padding=\"same\")\n",
    "        self.out_gate_ = nn.Conv2d(output_size//2, output_size, conv_filter, stride=conv_stride, padding=\"same\")\n",
    "        self.out_maxout = Maxout.apply\n",
    "        self.max_pool = nn.MaxPool2d(max_filter, stride=max_stride, ceil_mode=False)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "\n",
    "        nn.init.orthogonal_(self.reset_gate.weight)\n",
    "        nn.init.orthogonal_(self.update_gate.weight)\n",
    "        nn.init.orthogonal_(self.out_gate.weight)\n",
    "        nn.init.constant(self.reset_gate.bias, 0.)\n",
    "        nn.init.constant(self.update_gate.bias, 0.)\n",
    "        nn.init.constant(self.out_gate.bias, 0.)\n",
    "\n",
    "\n",
    "    def forward(self, input_, prev_state):\n",
    "\n",
    "        # get batch and spatial sizes\n",
    "        batch_size = input_.data.size()[0]\n",
    "        spatial_size = input_.data.size()[2:]\n",
    "#         print(batch_size, spatial_size)\n",
    "        \n",
    "        # generate empty prev_state, if None is provided\n",
    "        if prev_state is None:\n",
    "            state_size = [batch_size, self.output_size//2] + list(spatial_size)\n",
    "            if torch.cuda.is_available():\n",
    "                prev_state = Variable(torch.zeros(state_size)).cuda()\n",
    "            else:\n",
    "                prev_state = Variable(torch.zeros(state_size))\n",
    "\n",
    "        # data size is [batch, channel, height, width]\n",
    "        # stacked_inputs = torch.cat([input_, prev_state], dim=1)\n",
    "        # update = F.sigmoid(self.update_maxout(self.update_gate(stacked_inputs)))\n",
    "        # reset = F.sigmoid(self.reset_maxout(self.reset_gate(stacked_inputs)))\n",
    "        # # out_inputs = F.tanh(self.out_gate(torch.cat([input_, prev_state * reset], dim=1)))\n",
    "#         print(input_.shape, prev_state.shape)\n",
    "        z_t_n = self.sigmoid(self.update_maxout(self.update_gate(input_)+self.update_gate_(prev_state)))\n",
    "        r_t_n = self.sigmoid(self.reset_maxout(self.reset_gate(input_)+self.reset_gate_(prev_state)))\n",
    "#         print(\"z_t_n.shape, r_t_n.shape, prev_state.shape\", z_t_n.shape, r_t_n.shape, prev_state.shape)\n",
    "#         print(\"(r_t_n * prev_state).shape\", torch.mul(r_t_n, prev_state).shape)\n",
    "        hidden_ = self.tanh(self.out_maxout(self.out_gate(input_)+self.out_gate_(r_t_n * prev_state)))\n",
    "#         print(z_t_n.shape, r_t_n.shape, prev_state.shape, hidden_.shape)\n",
    "        new_state = z_t_n * prev_state + (1 - z_t_n) * hidden_\n",
    "\n",
    "        return self.max_pool(new_state), hidden_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "55fb9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRCNN(nn.Module):\n",
    "    def __init__(self, classes_num):\n",
    "        super().__init__()\n",
    "        self.GRCU_1 = ConvGRUCell(1, 16, (5, 5), (1, 1), (2, 1), (2, 1)) # (input_size, hidden_size, conv_filter, conv_stride, max_filter, max_stride)\n",
    "        self.GRCU_2 = ConvGRUCell(8, 32, (3, 3), (1, 1), (2, 1), (2, 1))\n",
    "        self.GRCU_3 = ConvGRUCell(16, 16, (3, 3), (1, 1), (2, 1), (2, 1))\n",
    "        self.fc = nn.Linear(8*32*32, 480*2)\n",
    "        self.maxout = Maxout.apply\n",
    "        self.fc_class = nn.Linear(480, classes_num)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "        self.window_size = 32\n",
    "        self.step = 10\n",
    "        \n",
    "    def forward(self, frames):\n",
    "#         print(frames.shape)\n",
    "        h_1 = None\n",
    "#         print(h_1.shape)\n",
    "        h_2 = None\n",
    "        h_3 = None\n",
    "        for t in range(int((len(frames[0][0][0])-self.window_size)/self.step)+1):\n",
    "            frame = torch.from_numpy(frames[:, :, :, t*self.step: t*self.step+self.window_size])\n",
    "#             print(frame.shape, h_1.shape)\n",
    "            y, h_1 = self.GRCU_1(frame, h_1)\n",
    "#             print(y.shape, h_1.shape)\n",
    "            y, h_2 = self.GRCU_2(y, h_2)\n",
    "            y, h_3 = self.GRCU_3(y, h_3)\n",
    "#             print(y)\n",
    "#         y = self.fc(y)\n",
    "        y = self.fc(y.flatten())\n",
    "#         print(y.shape)\n",
    "        y = self.maxout(y.reshape(1, 480*2, 1, 1)).flatten()\n",
    "#         print(y.shape)\n",
    "        classes = self.fc_class(y)\n",
    "        return self.softmax(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "1358f38d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-376-ffea9b6469c0>:113: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.reset_gate.bias, 0.)\n",
      "<ipython-input-376-ffea9b6469c0>:114: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.update_gate.bias, 0.)\n",
      "<ipython-input-376-ffea9b6469c0>:115: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.out_gate.bias, 0.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.6832037  -0.57169783 -0.55686945 ...  0.05938715 -0.13023205\n",
      "    -0.7771059 ]\n",
      "   [-0.9924119  -0.78656864 -0.61241287 ...  0.4642063  -0.32322216\n",
      "    -0.77545226]\n",
      "   [-0.32168755 -0.25977463 -0.19285311 ...  0.43186578  0.29145613\n",
      "    -0.22066562]\n",
      "   ...\n",
      "   [ 1.8729985   1.9845482   1.8347391  ...  1.7656589   1.8738041\n",
      "     1.8321075 ]\n",
      "   [ 1.8718315   1.7921361   1.8735186  ...  1.87458     1.8177145\n",
      "     1.8618876 ]\n",
      "   [ 1.8169066   1.7729185   1.786942   ...  1.7825811   1.8691953\n",
      "     1.8863722 ]]]]\n",
      "torch.Size([20, 16, 50, 32])\n",
      "torch.Size([10])\n",
      "tensor([0.1072, 0.0777, 0.1008, 0.1017, 0.0991, 0.1220, 0.1018, 0.0909, 0.1032,\n",
      "        0.0957], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = GRCNN(10)\n",
    "# for flac in db.index[:6]:\n",
    "# #     print(flac)\n",
    "#     with open(\"MGDs/\"+flac[\"name\"]+\".npy\", \"rb\") as file:\n",
    "#         MGD = np.load(file).reshape(257, -1, 1)\n",
    "#     with open(\"STFTs/\"+flac[\"name\"]+\".npy\", \"rb\") as file:\n",
    "#         STFT = np.load(file).reshape(1, 1, 256, -1)\n",
    "# #     print(MGD.shape, STFT[:, :, :, :31].shape)\n",
    "# #     print(torch.from_numpy(STFT[:, :, :, :32]).shape)\n",
    "# #     conv = nn.Conv2d(1, 16, (5, 5), stride=(1, 1), padding=\"same\")\n",
    "# #     output = conv(torch.from_numpy(STFT[:, :, :, :32]))\n",
    "# #     print(output.shape)\n",
    "#     outputs = model(STFT)\n",
    "#     print(outputs.shape)\n",
    "# print(os.chdir(\"..\"))\n",
    "with open(\"./STFTs/LA_T_1001169.npy\", \"rb\") as file:\n",
    "    STFT = np.load(file).reshape([1, 1, 256, -1])\n",
    "STFT = (STFT - np.mean(STFT)) / np.std(STFT)\n",
    "print(STFT)\n",
    "output = model(STFT)\n",
    "print(input.shape)\n",
    "print(output.shape)\n",
    "print(output)\n",
    "# tensor([0.1120, 0.0947, 0.1091, 0.0973, 0.1256, 0.1022, 0.0839, 0.0925, 0.0881, 0.0944], grad_fn=<SoftmaxBackward>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07c151e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7909, -0.6654,  1.3372, -1.7296,  0.1955,  0.5792, -0.7481, -0.0869,\n",
      "          0.0819,  1.9487,  2.2764, -0.7831,  1.0426,  0.5207,  0.1649,  0.8151,\n",
      "         -0.0274,  1.5615, -0.8928,  0.3207, -1.3114,  0.4394, -1.1950,  0.2414,\n",
      "          1.2117,  0.1229,  1.0073, -0.3994, -0.9846,  0.5623]])\n",
      "0\n",
      "tensor([ 1.7909, -0.6654,  1.3372, -1.7296,  0.1955,  0.5792])\n",
      "1\n",
      "tensor([ 1.3372, -1.7296,  0.1955,  0.5792, -0.7481, -0.0869])\n",
      "2\n",
      "tensor([ 0.1955,  0.5792, -0.7481, -0.0869,  0.0819,  1.9487])\n",
      "3\n",
      "tensor([-0.7481, -0.0869,  0.0819,  1.9487,  2.2764, -0.7831])\n",
      "4\n",
      "tensor([ 0.0819,  1.9487,  2.2764, -0.7831,  1.0426,  0.5207])\n",
      "5\n",
      "tensor([ 2.2764, -0.7831,  1.0426,  0.5207,  0.1649,  0.8151])\n",
      "6\n",
      "tensor([ 1.0426,  0.5207,  0.1649,  0.8151, -0.0274,  1.5615])\n",
      "7\n",
      "tensor([ 0.1649,  0.8151, -0.0274,  1.5615, -0.8928,  0.3207])\n",
      "8\n",
      "tensor([-0.0274,  1.5615, -0.8928,  0.3207, -1.3114,  0.4394])\n",
      "9\n",
      "tensor([-0.8928,  0.3207, -1.3114,  0.4394, -1.1950,  0.2414])\n",
      "10\n",
      "tensor([-1.3114,  0.4394, -1.1950,  0.2414,  1.2117,  0.1229])\n",
      "11\n",
      "tensor([-1.1950,  0.2414,  1.2117,  0.1229,  1.0073, -0.3994])\n",
      "12\n",
      "tensor([ 1.2117,  0.1229,  1.0073, -0.3994, -0.9846,  0.5623])\n"
     ]
    }
   ],
   "source": [
    "frames = torch.randn(1, 30)\n",
    "print(frames)\n",
    "def con_frames(frames):\n",
    "    for t in range(int((len(frames[0])-6)/2)+1):\n",
    "        print(t)\n",
    "        frame = frames[0][t*2: t*2+6]\n",
    "        print(frame)\n",
    "con_frames(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b236209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "print(x)\n",
    "# with open('test.npy', 'wb') as f:\n",
    "#     np.save(f, x)\n",
    "    \n",
    "with open(\"test.npy\", \"rb\") as file:\n",
    "    data = np.load(file)\n",
    "print(data == x)\n",
    "\n",
    "class Spectral_Features:\n",
    "    def __init__(self, path):\n",
    "        pass\n",
    "        \n",
    "    def extract_features(self, dest):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e27f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_phase = np.loadtxt(\"grp_phase.mat\")\n",
    "# cep = np.loadtxt(\"cep.mat\")\n",
    "# ts = np.loadtxt(\"ts.mat\")\n",
    "# print(grp_phase.shape)\n",
    "# print(cep.shape)\n",
    "# print(ts.shape)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "\n",
    "path = \"/media/ssd1T/antispoof/2019/LA\"\n",
    "# train_list = pd.read_csv(path, header=None, delim_whitespace=True)\n",
    "# # print(train_list.at[0,])\n",
    "# for row in train_list.iterrows():\n",
    "#     print(row[1][1])\n",
    "#     break\n",
    "    \n",
    "    \n",
    "class Database:\n",
    "    def __init__(self, index_path, data_path):\n",
    "        self.index_path = index_path\n",
    "        self.data_path = data_path\n",
    "        \n",
    "        self.index = self.generate_index(pd.read_csv(self.index_path, header=None, delim_whitespace=True))\n",
    "        \n",
    "    def generate_index(self, index_):\n",
    "        index = []\n",
    "        for row in index_.iterrows():\n",
    "            index.append({\"index\": row[0], \"id\": row[1][0], \"name\": row[1][1], \"label\": {\"type\": row[1][3], \"gender\": row[1][4]}})\n",
    "        return index\n",
    "        \n",
    "    def generate_MGD(self, dest, matlab_dir=\"matlab\"):\n",
    "        os.chdir(matlab_dir)    \n",
    "        for flac in self.index:\n",
    "#             print(os.getcwd())\n",
    "            bashCommand = \"\"\"octave --eval 'run(\"{}.flac\", \"{}\", \"{}\")'\"\"\".format(self.data_path+\"/\"+flac[\"name\"], flac[\"name\"], \"../\"+dest)\n",
    "#             print(bashCommand)\n",
    "            process = os.system(bashCommand)\n",
    "#             output, error = process.communicate()\n",
    "#             print(process)\n",
    "            grp_phase = np.loadtxt(\"../\"+dest+\"/\"+flac[\"name\"]+\".mat\")\n",
    "#             print(grp_phase)\n",
    "            with open(\"../\"+dest+\"/\"+flac[\"name\"]+'.npy', 'wb') as f:\n",
    "                np.save(f, grp_phase)\n",
    "            os.remove(\"../\"+dest+\"/\"+flac[\"name\"]+'.mat')\n",
    "#             break\n",
    "        os.chdir(\"..\")\n",
    "        \n",
    "    def generate_STFT(self, dest):\n",
    "        # print(waveform.numpy())\n",
    "#         print(len(waveform[0]))\n",
    "        n_fft = 1024\n",
    "       \n",
    "        window = \"blackman\"\n",
    "\n",
    "        n_mels = 256\n",
    "        fmin = 20\n",
    "        fmax = 8000\n",
    "        \n",
    "        for flac in self.index:\n",
    "            waveform, sample_rate = torchaudio.load(self.data_path+\"/\"+flac[\"name\"]+\".flac\")\n",
    "#             print(waveform)\n",
    "            win_length = int(np.ceil(0.025*sample_rate))\n",
    "            hop_length = int(np.ceil(0.010*sample_rate))\n",
    "            X = librosa.stft(waveform.numpy()[0], n_fft, hop_length, win_length, window, center=True)\n",
    "        #     print(np.abs(X).shape)\n",
    "            frames = np.log(librosa.feature.melspectrogram(y=waveform.numpy()[0], sr=sample_rate, S=X, n_mels=n_mels, fmin=fmin, fmax=fmax) + 1e-6)\n",
    "            with open(\"../\"+dest+\"/\"+flac[\"name\"]+'.npy', 'wb') as f:\n",
    "                np.save(f, frames)\n",
    "\n",
    "db = Database(path+\"/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\", path+\"/ASVspoof2019_LA_train/flac\")\n",
    "# db.generate_MGD(\"MGDs\", \"/home/tomtony/Sync/GRCNN/matlab\")\n",
    "# db.generate_STFT(\"STFTs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4caaa29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7708e+20, 2.2945e+02, 3.9920e+24, 4.1996e+12, 8.9683e-44])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "11353af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 256, 32])\n",
      "torch.Size([1, 8, 2, 256, 32])\n",
      "torch.Size([1, 8, 256, 32])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "\n",
    "\n",
    "class MaxoutConv(torch.nn.Module):\n",
    "    \"\"\"Maxout layer with convolution\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels,\n",
    "                 out_channels, kernel_size, padding):\n",
    "        \"\"\"\n",
    "        Define layers of maxout unit\n",
    "        :param in_channels: number of channel of input convolution\n",
    "        :type in_channels: :py:obj:`int`\n",
    "        :param out_channels: number of channel of output convolution\n",
    "        :type out_channels: :py:obj:`int`\n",
    "        :param kernel_size: size of the weight matrix to convolve\n",
    "        :type kernel_size: (:py:obj:`int`, :py:obj:`int`)\n",
    "        \"\"\"\n",
    "        super(MaxoutConv, self).__init__()\n",
    "\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                                    padding=padding)\n",
    "\n",
    "        self.BN = torch.nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, _input, is_norm=False):\n",
    "        \"\"\"\n",
    "        Pass the input to the maxout layer\n",
    "        :param _input: input to the maxout layer\n",
    "                       input is expected to have channel dimension\n",
    "        :type _input: :py:class:`torch.Tensor`\n",
    "        \"\"\"\n",
    "        z = self.conv(_input)\n",
    "        if is_norm:\n",
    "            z = self.BN(z)\n",
    "        print(\"z.shape: \", z.shape)\n",
    "        # (batch size, channels, height, width)\n",
    "        h = torch.max(z, 1).values     # take max operation from first dimension(channel)\n",
    "        # Insert 1 as channel dimension to h\n",
    "        print(\"h.shape: \", h.shape)\n",
    "        hshape = h.shape\n",
    "        h = h.reshape(*([hshape[0]] + [1] + list(hshape[1:])))\n",
    "        return h\n",
    "\n",
    "input = torch.randn(16, 256, 32).reshape(1, 16, 256, 32)\n",
    "# maxout = MaxoutConv(18, 9, 5, \"same\")\n",
    "print(input.shape)\n",
    "# output = maxout(input)\n",
    "# print(output.shape)\n",
    "\n",
    "\n",
    "# m = nn.Dropout(p=0.5)\n",
    "# input = torch.randn(20, 16)\n",
    "# output = m(input)\n",
    "# print(input.shape)\n",
    "# print(output.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Maxout(Function):\n",
    "\n",
    "    # Note that both forward and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input):\n",
    "        x = input\n",
    "        max_out=2    #Maxout Parameter\n",
    "        kernels = x.shape[1]  # to get how many kernels/output\n",
    "        feature_maps = int(kernels / max_out)\n",
    "        out_shape = (x.shape[0], feature_maps, max_out, x.shape[2], x.shape[3])\n",
    "#         print(x.shape)\n",
    "        x= x.view(out_shape)\n",
    "        print(x.shape)\n",
    "        y, indices = torch.max(x[:, :, :], 2)\n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.indices=indices\n",
    "        ctx.max_out=max_out\n",
    "        return y\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input1,indices,max_out= ctx.saved_variables[0],Variable(ctx.indices),ctx.max_out\n",
    "        input=input1.clone()\n",
    "        for i in range(max_out):\n",
    "            a0=indices==i\n",
    "            input[:,i:input.data.shape[1]:max_out]=a0.float()*grad_output\n",
    "      \n",
    "\n",
    "        return input\n",
    "\n",
    "maxout = Maxout.apply\n",
    "output = maxout(input)\n",
    "print(output.shape)\n",
    "# print(input)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "53ec3d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 50, 32]) torch.Size([20, 16, 25, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x32 and 8192x960)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-384-e1dda9464b88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x32 and 8192x960)"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, 16, 256, 32)\n",
    "b = torch.randn(1, 16, 256, 32)\n",
    "torch.mul(a, b).shape\n",
    "\n",
    "# pool of square window of size=3, stride=2\n",
    "m = nn.MaxPool2d(3, stride=2)\n",
    "# pool of non-square window\n",
    "m = nn.MaxPool2d((2, 1), stride=(2, 1))\n",
    "input = torch.randn(20, 16, 50, 32)\n",
    "output = m(input)\n",
    "print(input.shape, output.shape)\n",
    "\n",
    "x = torch.randn(1, 8, 32, 32)\n",
    "fc = nn.Linear(8*32*32, 480*2)\n",
    "y = fc(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "4a297dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-434-23c7a651f6f0>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.array([[1, 2, 3], [1], [2, 2, 2, 2, 2], [1, 1, 1], [3, 3, 3], [1, 2, 3], [1], [4, 2, 1, 1, 1, 1, 1], [1, 1, 1]])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-434-23c7a651f6f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Create DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "label = np.zeros(12)\n",
    "# print(label)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# Create toy data\n",
    "x = np.linspace(start=1, stop=10, num=10)\n",
    "x = np.array([np.random.normal(size=len(x)) for i in range(100)])\n",
    "x = np.array([[1, 2, 3], [1], [2, 2, 2, 2, 2], [1, 1, 1], [3, 3, 3], [1, 2, 3], [1], [4, 2, 1, 1, 1, 1, 1], [1, 1, 1]])\n",
    "# x = torch.from_numpy(x)\n",
    "print(x.shape)\n",
    "# Create DataLoader\n",
    "dataset = torch.from_numpy(x).float()\n",
    "print(x.shape)\n",
    "dataloader = data_utils.DataLoader(dataset, batch_size=32)\n",
    "batch = next(iter(dataloader))\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "6a0046d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021_08_08-2125\n",
      "tensor([-0.2889, -0.6835,  0.0709])\n",
      "tensor([ 0.6768,  0.3287, -0.0517])\n",
      "tensor([-0.2889, -0.6835,  0.0709,  0.6768,  0.3287, -0.0517])\n",
      "[1 2 3 4]\n",
      "torch.Size([6])\n",
      "torch.Size([2, 480])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now().strftime(\"%Y_%m_%d-%H%M\")\n",
    "print(now)\n",
    "\n",
    "a = torch.Tensor()\n",
    "b = torch.randn(3)\n",
    "print(b)\n",
    "a = torch.cat((a, b))\n",
    "b = torch.randn(3)\n",
    "print(b)\n",
    "a = torch.cat((a, b))\n",
    "print(a)\n",
    "\n",
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4])\n",
    "c = np.concatenate((a, b), axis=0)\n",
    "print(c)\n",
    "\n",
    "\n",
    "a = torch.randn(3)\n",
    "b = torch.randn(3)\n",
    "c = torch.cat([a, b])\n",
    "print(c.shape)\n",
    "\n",
    "m = nn.Dropout(p=0.2)\n",
    "input = torch.randn(20, 1, 3)\n",
    "output = m(input)\n",
    "# print(output)\n",
    "\n",
    "a = torch.randn(480)\n",
    "b = torch.randn(480)\n",
    "c = torch.stack((a, b))\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "778c556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 sad\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "a = [1, \"sad\", 3]\n",
    "for i, data in enumerate(a):\n",
    "    print(i, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
